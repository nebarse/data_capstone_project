{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bce902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# joining the path and creating list of paths to read all csv files in data2 folder\n",
    "dataframes = []\n",
    "\n",
    "for files in glob.glob(r'C:\\Users\\nebar\\Desktop\\project\\data2\\upc12\\*.xlsx'):\n",
    "\n",
    "    print(files)\n",
    "\n",
    "    data = pd.read_excel(files)\n",
    "\n",
    "    dataframes.append(data)\n",
    "\n",
    "data12_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "data12_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0fcf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import the customer detail cleaned data for upc 12\n",
    "final2_1 = pd.read_excel(r'C:\\Users\\nebar\\Desktop\\project\\data2\\final2_1.xlsx')\n",
    "\n",
    "final2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4252a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#to avoid confusion while creating total connection, rename Newegg Business, amazon and walmart marekt places as Newegg.com, amazon and walmart\n",
    "data12_df['Merchant'] = data12_df['Merchant'].str.replace('Amazon Marketplace New|Amazon Marketplace Used', 'Amazon.com', regex=True)\n",
    "\n",
    "data12_df['Merchant']  = data12_df['Merchant'].str.replace('Walmart Marketplace|Wal-Mart.com', 'Walmart', regex = True)\n",
    "                     \n",
    "data12_df['Merchant']  = data12_df['Merchant'].str.replace('Newegg Business', 'Newegg.com', regex = True)\n",
    "                   \n",
    "data12_df['Merchant'] = data12_df['Merchant'].str.replace('1-800Lighting', '1800lighting.com', regex = True)              \n",
    "\n",
    "data12_df['Merchant']  = data12_df['Merchant'].str.replace('Younkers(Bon-Ton)', 'Bon-Ton',regex = True)\n",
    "                       \n",
    "data12_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates using multiple variables\n",
    "data12_df = pd.DataFrame(data12_df, columns=[\"EAN\", \"Title\", \"Merchant\",\"last_updated\"])\n",
    "\n",
    "duplicate = data12_df[data12_df.duplicated()]\n",
    "\n",
    "print(\"Duplicate Rows :\")\n",
    "\n",
    "print(duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the duplicates \n",
    "data12_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e41b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the records with null value for the merchant variable\n",
    "missing_values = pd.notnull(data12_df[\"Merchant\"])\n",
    "\n",
    "data12_filtered  = data12_df[missing_values]\n",
    "\n",
    "data12_filtered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0bc663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking out the time part\n",
    "data12_filtered['last_updated'] = data12_filtered['last_updated'].apply(lambda x: ', '.join(set([part[:10] for part in x.split(', ')])))\n",
    "\n",
    "data12_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to put similar ean and title together to avoid redundancy while creating the total connections\n",
    "data12_output = data12_filtered.groupby(['EAN','Title']).agg(pd.Series.tolist)\n",
    "\n",
    "data12_scraped = data12_output.reset_index()\n",
    "\n",
    "data12_scraped = pd.DataFrame(data12_scraped)\n",
    "\n",
    "data12_scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f57e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the total connection for each unique id\n",
    "data12_scraped ['Total_connections'] = data12_scraped['Merchant'].apply(lambda x: len(set(x)))\n",
    "\n",
    "data12_scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dbcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make ean as string\n",
    "data12_scraped['EAN'] = data12_scraped['EAN'].astype(str)\n",
    "\n",
    "data12_scraped.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc0cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the customer details datatypes\n",
    "final2_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the final cleaned data and datascraped\n",
    "data12_scraped_output = pd.merge(data12_scraped, final2_1 , left_on = \"EAN\",right_on = \"CONSUMERPACKAGECODE\")\n",
    "\n",
    "data12_scraped_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrange the total_connections and total_retailer_connections column \n",
    "data12_scraped_new = data12_scraped_output.iloc[0:6775,[0,1,2,3,5,6,7,8,9,10,11,12,13,4]]\n",
    "\n",
    "data12_scraped_new['Missed_connections'] =  data12_scraped_new['Total_connections']- data12_scraped_new['Total_Retailer_Connections'] \n",
    "\n",
    "data12_scraped_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2604aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep the records with missed connections greater than 0\n",
    "data12_scraped_new = data12_scraped_new[data12_scraped_new.Missed_connections > 0]\n",
    " \n",
    "data12_scraped_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9ec65b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written to Excel File successfully.\n"
     ]
    }
   ],
   "source": [
    "#export the final file to excel\n",
    "df = pd.DataFrame(data12_scraped_new)\n",
    "\n",
    "file_name = 'cleaned12_missed.xlsx'\n",
    "\n",
    "df.to_excel(file_name,index = False)\n",
    "\n",
    "print('DataFrame is written to Excel File successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad6709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
